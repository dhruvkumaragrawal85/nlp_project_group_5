{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11401883,"sourceType":"datasetVersion","datasetId":7141441}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision torchaudio\n!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n!pip install torch-geometric\n\n!pip install torch networkx scikit-learn sentence-transformers spacy\n!python -m spacy download en_core_web_sm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T12:01:05.528293Z","iopub.execute_input":"2025-04-14T12:01:05.528884Z","iopub.status.idle":"2025-04-14T12:01:25.002453Z","shell.execute_reply.started":"2025-04-14T12:01:05.528855Z","shell.execute_reply":"2025-04-14T12:01:25.001595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport torch\nimport spacy\nimport numpy as np\nfrom tqdm import tqdm\nfrom sentence_transformers import SentenceTransformer\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import GCNConv, GAE\nfrom torch_geometric.utils import from_scipy_sparse_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom scipy.sparse import lil_matrix\nfrom torch_geometric.utils import negative_sampling\n\n# Load models\nnlp = spacy.load(\"en_core_web_sm\")\nembedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n# ========== Data Processing ==========\n\ndef get_edges_and_labels(dialogue, clause_indices):\n    edges = []\n    for i, turn in enumerate(dialogue):\n        if \"emotion\" in turn and turn[\"emotion\"] != \"neutral\":\n            if \"expanded emotion cause evidence\" in turn:\n                for j in turn[\"expanded emotion cause evidence\"]:\n                    try:\n                        cause_turn = int(str(j).strip()) - 1\n                        if cause_turn in clause_indices and i in clause_indices:\n                            from_idx = clause_indices[i]\n                            to_idx = clause_indices[cause_turn]\n                            edges.append((from_idx, to_idx))\n                    except ValueError:\n                        # Skip malformed cause evidence like 'b', '?', etc.\n                        continue\n    return edges\n\ndef process_dialogue(dialogue):\n    clauses = []\n    clause_turn_map = {}\n    turn_clause_indices = {}\n    clause_idx = 0\n\n    for i, turn in enumerate(dialogue):\n        doc = nlp(turn[\"utterance\"])\n        turn_clause_indices[i] = []\n        for sent in doc.sents:\n            clause_text = sent.text.strip()\n            if clause_text:\n                clauses.append(clause_text)\n                clause_turn_map[clause_idx] = i\n                turn_clause_indices[i].append(clause_idx)\n                clause_idx += 1\n\n    if not clauses:\n        return None\n\n    embeddings = embedder.encode(clauses)\n    x = torch.tensor(embeddings, dtype=torch.float)\n\n    # Get positive edges (emotion-cause)\n    pos_edges = get_edges_and_labels(dialogue, {v: k for k, v in clause_turn_map.items()})\n    \n    # Build undirected graph with syntactic similarities (co-reference, entity)\n    adj = lil_matrix((len(clauses), len(clauses)))\n    for i in range(len(clauses)):\n        for j in range(i + 1, len(clauses)):\n            if has_grammatical_connection(clauses[i], clauses[j]):\n                adj[i, j] = 1\n                adj[j, i] = 1\n\n    edge_index, _ = from_scipy_sparse_matrix(adj)\n    return Data(x=x, edge_index=edge_index, pos_edge_index=torch.tensor(pos_edges).t() if pos_edges else None)\n\ndef has_grammatical_connection(a, b):\n    doc_a = nlp(a)\n    doc_b = nlp(b)\n    ents_a = {ent.text.lower() for ent in doc_a.ents}\n    ents_b = {ent.text.lower() for ent in doc_b.ents}\n    if ents_a & ents_b:\n        return True\n    return any(\n        t1.text.lower() == t2.text.lower() and t1.dep_ in (\"nsubj\", \"dobj\")\n        for t1 in doc_a for t2 in doc_b\n    )\n\n# ========== Load Dataset ==========\n\ndef load_data(path):\n    with open(path) as f:\n        data = json.load(f)\n    return [process_dialogue(conv[0]) for conv in data.values() if conv]\n\ntrain_data = [d for d in load_data(\"/kaggle/input/nlp-data/dailydialog_train.json\") if d]\ntest_data = [d for d in load_data(\"/kaggle/input/nlp-data/dailydialog_test.json\") if d]\n\n# ========== Model ==========\n\nclass Encoder(torch.nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv1 = GCNConv(in_channels, 128)\n        self.conv2 = GCNConv(128, out_channels)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index).relu()\n        return self.conv2(x, edge_index)\n\nmodel = GAE(Encoder(in_channels=384, out_channels=64))\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n\n# ========== Train & Eval ==========\n\n\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\n\n# Tracking metrics\nlosses = []\naucs = []\nprecisions = []\nrecalls = []\nf1s = []\n\n\nfor epoch in range(10):\n    model.train()\n    total_loss = 0\n    for data in train_data:\n        optimizer.zero_grad()\n        z = model.encode(data.x, data.edge_index)\n        if data.pos_edge_index is None:\n            continue\n        loss = model.recon_loss(z, data.pos_edge_index)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    avg_loss = total_loss / len(train_data)\n    losses.append(avg_loss)\n\n    # Evaluation\n    model.eval()\n    epoch_aucs = []\n    epoch_precisions = []\n    epoch_recalls = []\n    epoch_f1s = []\n\n    with torch.no_grad():\n        for data in test_data:\n            if data.pos_edge_index is None:\n                continue\n            z = model.encode(data.x, data.edge_index)\n            pos_pred = model.decoder(z, data.pos_edge_index).view(-1)\n            pos_true = torch.ones_like(pos_pred)\n\n            neg_edge_index = negative_sampling(\n                edge_index=data.edge_index, num_nodes=z.size(0),\n                num_neg_samples=pos_pred.size(0)\n            )\n            neg_pred = model.decoder(z, neg_edge_index).view(-1)\n            neg_true = torch.zeros_like(neg_pred)\n\n            pred = torch.cat([pos_pred, neg_pred])\n            true = torch.cat([pos_true, neg_true])\n\n            pred_binary = (pred > 0.5).int().cpu()\n            true_binary = true.int().cpu()\n\n            epoch_aucs.append(roc_auc_score(true_binary, pred.cpu()))\n            epoch_precisions.append(precision_score(true_binary, pred_binary, zero_division=0))\n            epoch_recalls.append(recall_score(true_binary, pred_binary, zero_division=0))\n            epoch_f1s.append(f1_score(true_binary, pred_binary, zero_division=0))\n\n    aucs.append(np.mean(epoch_aucs))\n    precisions.append(np.mean(epoch_precisions))\n    recalls.append(np.mean(epoch_recalls))\n    f1s.append(np.mean(epoch_f1s))\n\n    print(f\"Epoch {epoch+1:02d} | Loss: {avg_loss:.4f} | AUC: {aucs[-1]:.4f} | \"\n          f\"Precision: {precisions[-1]:.4f} | Recall: {recalls[-1]:.4f} | F1: {f1s[-1]:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T12:05:38.149882Z","iopub.execute_input":"2025-04-14T12:05:38.150651Z","iopub.status.idle":"2025-04-14T12:40:21.295773Z","shell.execute_reply.started":"2025-04-14T12:05:38.150617Z","shell.execute_reply":"2025-04-14T12:40:21.294863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ======== Plotting Metrics =========\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(16, 10))\n\n# Loss\nplt.subplot(2, 2, 1)\nplt.plot(losses, marker='o', label='Loss')\nplt.title(\"Training Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.grid(True)\nplt.legend()\n\n# AUC\nplt.subplot(2, 2, 2)\nplt.plot(aucs, marker='o', label='AUC', color='orange')\nplt.title(\"AUC Score\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"AUC\")\nplt.grid(True)\nplt.legend()\n\n# Precision / Recall\nplt.subplot(2, 2, 3)\nplt.plot(precisions, marker='o', label='Precision', color='green')\nplt.plot(recalls, marker='s', label='Recall', color='blue')\nplt.title(\"Precision & Recall\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Score\")\nplt.grid(True)\nplt.legend()\n\n# F1\nplt.subplot(2, 2, 4)\nplt.plot(f1s, marker='d', label='F1 Score', color='purple')\nplt.title(\"F1 Score\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Score\")\nplt.grid(True)\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T17:46:43.269235Z","iopub.execute_input":"2025-04-14T17:46:43.269758Z","iopub.status.idle":"2025-04-14T17:46:44.141463Z","shell.execute_reply.started":"2025-04-14T17:46:43.269733Z","shell.execute_reply":"2025-04-14T17:46:44.140549Z"}},"outputs":[],"execution_count":null}]}